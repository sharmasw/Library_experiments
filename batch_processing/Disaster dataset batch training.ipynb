{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a328af-9108-4ddf-8b1d-1c8c5758bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Print the version of TensorFlow\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check if TensorFlow can access the GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPUs available:\", gpus)\n",
    "else:\n",
    "    print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551e46d9-4135-46e1-8fbc-621b1d52d0b4",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe5ed2-23bc-43c1-956c-baef26dfc162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "from chromadb.utils import embedding_functions\n",
    "# sent_emb=embedding_functions.SentenceTransformerEmbeddingFunction()\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Input\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "# keras.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a748ce-8427-4609-9a06-95108d49635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57eb398-e2e8-4178-b7e1-23efae279ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc4d44-bb74-4461-8e38-52a1f04c87a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_2 = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def sent_emb(text):\n",
    "    inputs=tokenizer(text,return_tensors=\"tf\",padding=True, truncation=True)\n",
    "    outputs = model_2(inputs)\n",
    "    return tf.reduce_mean(outputs.last_hidden_state,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea426109-0ebf-47c9-a1a9-e233ad0657ba",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb04c911-9b2a-452f-be74-5526e0a323be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('nlp-getting-started/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca8c97-f2a6-4e09-8e06-fc009bf96380",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aacdd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7627091-6dca-477c-9a6a-63a795736b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f90acf-2519-445e-8eac-6391b873679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b805ef-11fe-4567-993f-5992e1422dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X , val_X = train_test_split(data,test_size=.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0cee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape , val_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a0246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_emb(['kashdkasjd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fd3258-0db5-4315-b058-c1b68c8c10ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train_X = sent_emb(list(train_X['text']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa20221-5e2c-4646-845e-7f3df876dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train_X = train_X[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364464f-39b1-4951-a6d1-c5f341346942",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_val_X = sent_emb(val_X['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c03d1-ba04-4abd-a7d9-2288b05c4bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_val_X = val_X[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed2b90-ecf3-4d48-95a9-fa98918dc1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train_X_= np.array(feature_train_X)\n",
    "feature_val_X_= np.array(feature_val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743c658b-8302-4f94-a23e-f31e9ab1b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train_X_.shape, feature_val_X_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13828e5f-1247-4486-8bd7-30dad2938463",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0092f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb([\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ebea82-59b3-4d78-a5d4-df067734a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "elm_len = len(sent_emb([\"text\"])[0])\n",
    "elm_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901cc161-9692-4d9a-98bc-7f74f5e5f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Input(shape=(elm_len,1)),\n",
    "#     keras.layers.Dense(500,activation=\"relu\"),\n",
    "#     keras.layers.Dense(300,activation=\"relu\"),\n",
    "#     keras.layers.Dense(200,activation=\"relu\"),\n",
    "#     keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "# ])\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "#     loss=keras.losses.BinaryCrossentropy(),\n",
    "#     metrics=[\n",
    "#         keras.metrics.BinaryAccuracy(),\n",
    "#         keras.metrics.FalseNegatives(),\n",
    "#     ],\n",
    "# )\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec54791-6625-49e9-9707-82fbf94845a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(elm_len,)))\n",
    "model.add(Dense(elm_len*2, activation='relu'))\n",
    "model.add(Dense(elm_len, activation='relu'))\n",
    "# Optional: Add another layer\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        keras.metrics.F1Score(),\n",
    "        keras.metrics.BinaryAccuracy(),\n",
    "    ],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe404ea5-4248-4e39-8f2d-98ef08be1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train_X_=np.array(label_train_X).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a49b36-f113-489c-a847-f4d96a575c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_val_X_=np.array(label_val_X).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c83b2ca-0d36-4b35-988b-f2865b8e516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train_X_.shape, label_train_X_.shape ,feature_val_X_.shape, label_val_X_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ca557a",
   "metadata": {},
   "source": [
    "## .fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d631a654",
   "metadata": {},
   "source": [
    "the .fit() function it makes assumptions:\n",
    "\n",
    "* The available RAM of the computer is enough to do the training.\n",
    "* Calling the model. fit method for a second time is not going to reinitialize our already trained weights, which means we can actually make  consecutive calls to fit if we want to and then manage it properly.\n",
    "* Processed data is itself used for training our network and our raw data will only fit into the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad43685e-0e75-4e7b-aa19-1983c920fdc4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=feature_train_X_,\n",
    "    y=label_train_X_,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    verbose=\"auto\",\n",
    "    validation_data=[feature_val_X_,label_val_X_],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e979950",
   "metadata": {},
   "source": [
    "## train_on_batch\n",
    "\n",
    "* when available memory is not enough for the complete data \n",
    "* train_on_batch allows you to expressly update weights based on a collection of samples you provide, without worrying about the fixed batch size.\n",
    "* one more example  for RL, controlling calls to model.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3934b900-b93a-4487-877b-f459730af719",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=50\n",
    "num_batches = len(data) // batch_size\n",
    "epochs=5\n",
    "epochs,num_batches,batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403f02c5-919e-4228-8c99-5552b2639637",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    acc_vals=[]\n",
    "    for i in tqdm(range(num_batches)):\n",
    "        # Get the batch of texts\n",
    "        batch_data = data['text'][i * batch_size:(i + 1) * batch_size]\n",
    "        batch_labels = data['target'][i * batch_size:(i + 1) * batch_size]\n",
    "        \n",
    "        # Generate embeddings for this batch using the LLM\n",
    "        feature_X = np.array(sent_emb(list(batch_data)))\n",
    "        label_X_=np.array(batch_labels).reshape(-1, 1)\n",
    "        \n",
    "        # Train the model on the batch\n",
    "        loss, f1, acc = model.train_on_batch(feature_X, label_X_)\n",
    "        acc_vals.append(acc)\n",
    "        \n",
    "    print(f'Batch {i + 1}/{num_batches}, Loss: {loss}, Accuracy: {sum(acc_vals)/num_batches}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e692f2-4b9f-4ba5-893f-c1a4a5b4da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c314b-f747-4dac-8e9f-b012d6b9c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val=model.predict(feature_val_X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9894d63-6671-4dc4-97dc-980a3a9aa763",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(label_val_X_, pred_val)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc_score(label_val_X_, pred_val):.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Random classifier line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec3b98-8988-4565-93f4-f389995a8cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "J = tpr - fpr\n",
    "best_threshold_index = np.argmax(J)\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "\n",
    "# Plot the best threshold\n",
    "plt.scatter(fpr[best_threshold_index], tpr[best_threshold_index], marker='o', color='red', label=f'Best Threshold: {best_threshold:.2f}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3eb581-3f22-473d-9201-c02c89475c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('nlp-getting-started/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a5588-f98c-4eae-a201-b03ba708ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f481da76-57b1-4656-abf7-9d7e2c3ecae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features= emb_fun(test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e56e90-ba23-4a2b-965c-3a34549920db",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat=np.array(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96326a30-114b-48ee-bb70-228657fdc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc11ae-1036-446c-95d7-0f989c8148c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predi = model.predict(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c2047-cadc-4888-a0e4-de9f094b4e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5939a27-7fda-4e7c-80ab-cb6ed1c906bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv('nlp-getting-started/sample_submission.csv')\n",
    "predi=np.where(predi <.56,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d6e80a-97fa-4100-9b71-6fedd175cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat((test_data[['id']],pd.DataFrame(predi,columns=['target'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3218625-d775-4b2e-9aea-70366baacf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28582493-cf3a-46b2-a004-b9604ef1eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('first_sub2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe9e84-1ab7-43c9-b723-174d3295dbb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
